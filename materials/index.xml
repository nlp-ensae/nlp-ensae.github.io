<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Course Material | NLP course</title>
    <link>https://ben-mlr.github.io/materials/</link>
      <atom:link href="https://ben-mlr.github.io/materials/index.xml" rel="self" type="application/rss+xml" />
    <description>Course Material</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 01 Feb 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ben-mlr.github.io/img/icon-192.png</url>
      <title>Course Material</title>
      <link>https://ben-mlr.github.io/materials/</link>
    </image>
    
    <item>
      <title>(1) Lecture 1: The Basics of NLP</title>
      <link>https://ben-mlr.github.io/materials/course1/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course1/</guid>
      <description>&lt;p&gt;In this lecture, we will introduce what is Natural Language Processing. We will introduce some core linguistics concepts to describe why NLP is challenging from a Machine Learning perspective. We will then describe the general modeling framework as well as an overview of NLP tasks. We will conclude with practical guidelines.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>(2) Lecture 2: Representing text into vectors </title>
      <link>https://ben-mlr.github.io/materials/course2/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course2/</guid>
      <description>

&lt;h1 id=&#34;representing-text-into-vectors&#34;&gt;Representing text into vectors&lt;/h1&gt;

&lt;p&gt;The first step when we do NLP is to represent tokens, sentences, documents into data structure that can useful in practice. For this purpose, we will present 3 main approaches: Hand-Crafted Representations of Text, Count-Based Representation of text, and Prediction-based representation of text.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>(3) Lecture 3: Deep Learning Methods for NLP</title>
      <link>https://ben-mlr.github.io/materials/course3/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course3/</guid>
      <description>

&lt;h1 id=&#34;deep-learning-methods-for-nlp&#34;&gt;Deep Learning Methods for NLP&lt;/h1&gt;

&lt;p&gt;This lecture presents Deep Learning techniques used in NLP. We cover the design and training principles. We present the Multi-Layer-Perceptron (MLP), Recurrent Architectures (RNN and LSTM) and the transformer architecture.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>(4) Lecture 4: Language Modeling</title>
      <link>https://ben-mlr.github.io/materials/course4/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course4/</guid>
      <description>

&lt;h1 id=&#34;language-modeling&#34;&gt;Language Modeling&lt;/h1&gt;

&lt;p&gt;Language modeling is one of the most challenging and useful tasks in NLP. In this lecture, we define what is language modeling and present how to do language modeling with Deep Learning architectures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>(5) Lecture 5: Sequence Labeling &amp; Classification</title>
      <link>https://ben-mlr.github.io/materials/course5/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course5/</guid>
      <description>

&lt;h1 id=&#34;sequence-labeling-classification&#34;&gt;Sequence Labeling &amp;amp; Classification&lt;/h1&gt;

&lt;p&gt;Given an input sequence of tokens, sequence Labeling consists in classifying each token by assigning it a label. In this lecture, after illustrating sequence labeling &amp;amp; classification with POS tagging, NER and Question Answering, we present how to do sequence labeling with Recurrent based models and transformer based models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>(6) Lecture 6: Sequence Generation</title>
      <link>https://ben-mlr.github.io/materials/course6/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course6/</guid>
      <description>

&lt;h1 id=&#34;sequence-generation&#34;&gt;Sequence Generation&lt;/h1&gt;

&lt;p&gt;Many NLP tasks, such as Machine Translation or Summarization, require to predict sequences of tokens. In this lecture, we introduce the encoder-decoder and show how it can be used for sequence generation tasks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lab 1: Introduction to textual data with Python</title>
      <link>https://ben-mlr.github.io/materials/lab-1/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/lab-1/</guid>
      <description>&lt;p&gt;This lab introduces basics processing operations required for any NLP experiments. After introducing preprocessing tools for data cleaning and tokenization, we compute some descriptive statistics on textual data.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Google Colab Notebook Student Version &lt;a href=&#34;https://drive.google.com/file/d/1QTrPCSsazALd4nfb4NTvzAqr9frYE6KI/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;ðŸ”—&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Full Handout Correction Google Colab Notebook &lt;a href=&#34;https://drive.google.com/file/d/1m8pW3Es-2I5mDdslz-NyBy_5016iVEPh/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;ðŸ”—&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Lab 2: Word Embeddings and their evaluation</title>
      <link>https://ben-mlr.github.io/materials/lab-2/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/lab-2/</guid>
      <description>&lt;p&gt;This lab explores representation learning techniques for words and documents. It explores models like tf-idf and Word2vec and develop quantitative and qualtiative evaluation methods.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Google Colab Notebook Student Version &lt;a href=&#34;https://drive.google.com/file/d/1QwmB0sT22ahwqITftWDaG6cXRS7lEicT/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;ðŸ”—&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Full Handout Correction Google Colab Notebook &lt;a href=&#34;https://drive.google.com/file/d/1rzlL6BZ9kIWRTietl0jkBOPY4-kElmEL/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;ðŸ”—&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Lab 3-4: Sequence Labeling and Sequence Classification with Deep Learning Models</title>
      <link>https://ben-mlr.github.io/materials/lab-3-4/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/lab-3-4/</guid>
      <description>&lt;p&gt;This lab implements, trains and evaluates sequence classification and labeling models based on Recurrent Neural Networks and transformer deep-learning architecture.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Google Colab Notebook Student Version &lt;a href=&#34;https://drive.google.com/file/d/1bzmwJsshvwpK7C8upmbPdyhJ9KVMphYr/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;ðŸ”—&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Full Handout Correction Google Colab Notebook [ðŸ”—]&lt;a href=&#34;https://drive.google.com/file/d/1EvaLnYRzBO1stvWv_q9IjmZr3tpGPfax/view?usp=sharing)&#34; target=&#34;_blank&#34;&gt;https://drive.google.com/file/d/1EvaLnYRzBO1stvWv_q9IjmZr3tpGPfax/view?usp=sharing)&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Lab 5: Machine Translation</title>
      <link>https://ben-mlr.github.io/materials/lab-5/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/lab-5/</guid>
      <description>&lt;p&gt;This lab introduces introduces machine translation and implements a simple encoder-decoder architecture in pytorch.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Google Colab Notebook Student Version &lt;a href=&#34;https://drive.google.com/file/d/15Iyit9ynK1xClvxrrRO-DWCk-UWax3T9/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;ðŸ”—&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Full Handout Correction Google Colab Notebook &lt;a href=&#34;https://drive.google.com/file/d/1zWJhZ4oWVDqSMdzoEO4RoPvoBE3O354p/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;ðŸ”—&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
