<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Course Material | NLP course</title>
    <link>https://ben-mlr.github.io/materials/</link>
      <atom:link href="https://ben-mlr.github.io/materials/index.xml" rel="self" type="application/rss+xml" />
    <description>Course Material</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 01 Feb 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ben-mlr.github.io/img/icon-192.png</url>
      <title>Course Material</title>
      <link>https://ben-mlr.github.io/materials/</link>
    </image>
    
    <item>
      <title>Lab 1: Introduction to textual data with Python</title>
      <link>https://ben-mlr.github.io/materials/lab-1/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/lab-1/</guid>
      <description>

&lt;h1 id=&#34;introduction-to-textual-data-with-python&#34;&gt;Introduction to textual data with python&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 1: The Basics of NLP</title>
      <link>https://ben-mlr.github.io/materials/course1/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course1/</guid>
      <description>&lt;p&gt;In this lecture, we will introduce what is Natural Language Processing. We will introduce some core linguistics concepts to describe why NLP is challenging from a Machine Learning perspective. We will then describe the general modeling framework as well as an overview of NLP tasks. We will conclude with practical guidelines.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Session 2: Representing text into vectors </title>
      <link>https://ben-mlr.github.io/materials/course2/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course2/</guid>
      <description>

&lt;h1 id=&#34;representing-text-into-vectors&#34;&gt;Representing text into vectors&lt;/h1&gt;

&lt;p&gt;The first step when we do NLP is to represent tokens, sentences, documents into data structure that can useful in practice. For this purpose, we will present 3 main approaches: Hand-Crafted Representations of Text, Count-Based Representation of text, and Prediction-based representation of text.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Session 3: Deep Learning Methods for NLP</title>
      <link>https://ben-mlr.github.io/materials/course3/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course3/</guid>
      <description>

&lt;h1 id=&#34;deep-learning-methods-for-nlp&#34;&gt;Deep Learning Methods for NLP&lt;/h1&gt;

&lt;p&gt;This lecture presents Deep Learning techniques used in NLP. We cover the design and training principles. We present the Multi-Layer-Perceptron (MLP), Recurrent Architectures (RNN and LSTM) and the transformer architecture.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Session 4: Language Modeling</title>
      <link>https://ben-mlr.github.io/materials/course4/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course4/</guid>
      <description>

&lt;h1 id=&#34;language-modeling&#34;&gt;Language Modeling&lt;/h1&gt;

&lt;p&gt;Language modeling is one of the most challenging and useful tasks in NLP. In this lecture, we define what is language modeling and present how to do language modeling with Deep Learning architectures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Session 5: Sequence Labeling &amp; Classification</title>
      <link>https://ben-mlr.github.io/materials/course5/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course5/</guid>
      <description>

&lt;h1 id=&#34;sequence-labeling-classification&#34;&gt;Sequence Labeling &amp;amp; Classification&lt;/h1&gt;

&lt;p&gt;Given an input sequence of tokens, sequence Labeling consists in classifying each token by assigning it a label. In this lecture, after illustrating sequence labeling &amp;amp; classification with POS tagging, NER and Question Answering, we present how to do sequence labeling with Recurrent based models and transformer based models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Session 6: Sequence Generation</title>
      <link>https://ben-mlr.github.io/materials/course6/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course6/</guid>
      <description>

&lt;h1 id=&#34;sequence-generation&#34;&gt;Sequence Generation&lt;/h1&gt;

&lt;p&gt;Many NLP tasks, such as Machine Translation or Summarization, require to predict sequences of tokens. In this lecture, we introduce the encoder-decoder and show how it can be used for sequence generation tasks.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
