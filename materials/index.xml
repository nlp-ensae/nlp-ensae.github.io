<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Course Material | NLP course</title>
    <link>https://ben-mlr.github.io/materials/</link>
      <atom:link href="https://ben-mlr.github.io/materials/index.xml" rel="self" type="application/rss+xml" />
    <description>Course Material</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 01 Feb 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ben-mlr.github.io/img/icon-192.png</url>
      <title>Course Material</title>
      <link>https://ben-mlr.github.io/materials/</link>
    </image>
    
    <item>
      <title>Session 1: The Why and What of NLP</title>
      <link>https://ben-mlr.github.io/materials/course1/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course1/</guid>
      <description>

&lt;h1 id=&#34;the-why-and-what-of-nlp&#34;&gt;The Why and What of NLP&lt;/h1&gt;

&lt;p&gt;This session is an introduction session to NLP. We first motivate the uses and potential uses of NLP. We then introduce some key linguistic concepts for NLP. Finally, we describe NLP in three standart pipelines.&lt;/p&gt;

&lt;h2 id=&#34;lecture-files-nlp-ensae-2021-lecture-1-pdf&#34;&gt;&lt;a href=&#34;https://ben-mlr.github.io/files/NLP-ENSAE-2021-lecture-1.pdf&#34;&gt;Lecture&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-https-colab-research-google-com-drive-1-l0k0j-25k2k-cd1td3nsbl3s68uogsn-usp-sharing&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1-L0K0J_25K2K-cD1tD3NsBL3s68UogSN?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-correction-https-colab-research-google-com-drive-1-4oafhazgwnztb1catiepvk-xj6sunnp-usp-sharing&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1-4OAfhAZGWNzTB1CAtIEPvK-xJ6SunnP?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab Correction&lt;/a&gt;&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Session 2: Representing text into vectors </title>
      <link>https://ben-mlr.github.io/materials/course2/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course2/</guid>
      <description>

&lt;h1 id=&#34;representing-text-into-vectors&#34;&gt;Representing text into vectors&lt;/h1&gt;

&lt;p&gt;This course covers representation learning techniques for Natural Language Processing with a specific focus on word representation. We start with feature based approaches. We then study continuous approaches using co-occurence matrices. We end with word embedding techniques such as word2vec.&lt;/p&gt;

&lt;h2 id=&#34;lecture-files-nlp-ensae-2021-lecture-2-pdf&#34;&gt;&lt;a href=&#34;https://ben-mlr.github.io/files/NLP-ENSAE-2021-lecture-2.pdf&#34;&gt;Lecture&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-https-drive-google-com-file-d-186km6os3jv3ek3apypmqfi5y3we2b3wt-view-usp-sharing&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/186km6os3jv3Ek3APYPmQFi5Y3we2b3Wt/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-correction-https-drive-google-com-file-d-1y9fc04hntspwmqjkk5yzjwwupdybzq9m-view-usp-sharing&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1Y9fC04hnTspwmqJkK5yZJWwUpDybzq9m/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab Correction&lt;/a&gt;&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Session 3: Task-specific Modeling of Text</title>
      <link>https://ben-mlr.github.io/materials/course3/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course3/</guid>
      <description>

&lt;h1 id=&#34;task-specific-modeling-of-text&#34;&gt;Task-specific Modeling of Text&lt;/h1&gt;

&lt;p&gt;This course covers a standart task-specific NLP pipeline. We present the preprocessing steps such as encoding and tokenization. We then focus on sequence labelling illustrated by POS (Part-of-Speech) tagging and Name-Entity Recognition (NER). Finally, we present the standard evaluation metrics for classification tasks.&lt;/p&gt;

&lt;h2 id=&#34;lecture-files-nlp-ensae-2021-lecture-3-pdf&#34;&gt;&lt;a href=&#34;https://ben-mlr.github.io/files/NLP-ENSAE-2021-lecture-3.pdf&#34;&gt;Lecture&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-https-drive-google-com-file-d-1tkjq4qrabejlp44zfirdwi-auubqt8kh-view-usp-sharing&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1tkjQ4QraBEjLP44ZFIRdWi_auUbQT8kH/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-correction-https-drive-google-com-file-d-1d18-uyyaf8mscg5f49fr87ewkvkh3jad-view-usp-sharing&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1D18-UYyAF8mScG5F49fr87EWkVkH3JaD/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab Correction&lt;/a&gt;&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Session 4: Neural Natural Language Processing</title>
      <link>https://ben-mlr.github.io/materials/course4/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course4/</guid>
      <description>

&lt;h1 id=&#34;neural-natural-language-processing&#34;&gt;Neural Natural Language Processing&lt;/h1&gt;

&lt;p&gt;This lecture presents the most standart deep learning architectures to build Natural Language Processing models. We consider Feed-Forward Neural Networks, Recurrent Neural Network and the Long-Short-Term Memory cell, Embedding layer and Attention Mechanisms. We present these architectures in the context of Sequence Labelling tasks.&lt;/p&gt;

&lt;h2 id=&#34;lecture-files-nlp-ensae-2021-lecture-4-pdf&#34;&gt;&lt;a href=&#34;https://ben-mlr.github.io/files/NLP-ENSAE-2021-lecture-4.pdf&#34;&gt;Lecture&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-https-drive-google-com-file-d-1tfykmid04xgmdhecw1rbo86t4kzmggpv-view-usp-sharing&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1TFYkMiD04xGMDHEcw1RBO86t4KZMGGPv/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-correction-https-drive-google-com-file-d-1fenhgud2vttft7pinvzsv-7sppbdq7ny-view-usp-sharing&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1FeNHGUd2VTTfT7PinvzsV-7sPpbdQ7NY/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab Correction&lt;/a&gt;&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Session 5: Language Modeling</title>
      <link>https://ben-mlr.github.io/materials/course5/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course5/</guid>
      <description>

&lt;h1 id=&#34;language-modeling&#34;&gt;Language Modeling&lt;/h1&gt;

&lt;p&gt;This lecture presents from a probabilistic perspective what is a language model and how to estimate a language model using statistical techniques and neural techniques.&lt;/p&gt;

&lt;h2 id=&#34;lecture-files-nlp-ensae-2021-lecture-5-pdf&#34;&gt;&lt;a href=&#34;https://ben-mlr.github.io/files/NLP-ENSAE-2021-lecture-5.pdf&#34;&gt;Lecture&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-https-colab-research-google-com-drive-1goe5ql9tdu17e9lvbwk0nmbgf4yhoj7t-usp-sharing&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1GoE5QL9tDu17E9lVbwK0nMBgF4YhoJ7t?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;lab-correction-https-colab-research-google-com-drive-17qcltinik1ehbgus7gzqrsduiylxlccu-usp-sharing&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/drive/17qCLtINIk1EhBgUs7gzqrsDUIylXlcCu?usp=sharing&#34; target=&#34;_blank&#34;&gt;Lab Correction&lt;/a&gt;&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Session 6: Transfer Learning with Neural Modeling for NLP</title>
      <link>https://ben-mlr.github.io/materials/course6/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ben-mlr.github.io/materials/course6/</guid>
      <description>

&lt;h1 id=&#34;transfer-learning-with-neural-modeling-for-nlp&#34;&gt;Transfer Learning with Neural Modeling for NLP&lt;/h1&gt;

&lt;p&gt;Transfer Learning has become ubiquitious to build state-of-the-art NLP models. This lecture presents Transfer Learning focusing on how to do Transfer Learning in NLP using word embedding techniques such as skip-gram and BERT.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
